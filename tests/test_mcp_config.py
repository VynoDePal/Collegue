#!/usr/bin/env python3
"""
Script de test pour la configuration MCP dynamique du LLM.
Teste la priorit√© de configuration et diff√©rents mod√®les.
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional

# Ajouter le r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

from collegue.config import Settings
from collegue.core.tool_llm_manager import ToolLLMManager

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_config_priority():
    """Test de la priorit√© de configuration MCP > ENV > DEFAULT."""
    print("\n" + "="*60)
    print("TEST DE PRIORIT√â DE CONFIGURATION")
    print("="*60)
    
    # Sauvegarder les valeurs actuelles
    original_env_model = os.environ.get("LLM_MODEL")
    original_env_key = os.environ.get("LLM_API_KEY")
    
    try:
        # Test 1: Valeurs par d√©faut uniquement
        print("\n1. Test avec valeurs par d√©faut:")
        if "LLM_MODEL" in os.environ:
            del os.environ["LLM_MODEL"]
        if "LLM_API_KEY" in os.environ:
            del os.environ["LLM_API_KEY"]
        
        settings = Settings()
        print(f"   - Mod√®le: {settings.llm_model}")
        print(f"   - API Key pr√©sente: {bool(settings.llm_api_key)}")
        
        # Test 2: Variables d'environnement
        print("\n2. Test avec variables d'environnement:")
        os.environ["LLM_MODEL"] = "openai/gpt-3.5-turbo"
        os.environ["LLM_API_KEY"] = "sk-env-test-key"
        
        settings = Settings()
        print(f"   - Mod√®le depuis ENV: {settings.llm_model}")
        print(f"   - API Key depuis ENV: {settings.llm_api_key[:20]}...")
        
        # Test 3: Param√®tres MCP (priorit√© maximale)
        print("\n3. Test avec param√®tres MCP (priorit√© max):")
        mcp_params = {
            "LLM_MODEL": "google/gemini-2.0-flash-exp:free",
            "LLM_API_KEY": "sk-mcp-test-key"
        }
        
        settings.update_from_mcp(mcp_params)
        print(f"   - Mod√®le depuis MCP: {settings.llm_model}")
        print(f"   - API Key depuis MCP: {settings.llm_api_key[:20]}...")
        
        # V√©rifier que MCP a priorit√© sur ENV
        assert settings.llm_model == "google/gemini-2.0-flash-exp:free", "MCP devrait avoir priorit√© sur ENV"
        assert settings.llm_api_key == "sk-mcp-test-key", "MCP API key devrait avoir priorit√©"
        
        print("\n‚úÖ Test de priorit√© r√©ussi: MCP > ENV > DEFAULT")
        
    finally:
        # Restaurer les valeurs originales
        if original_env_model:
            os.environ["LLM_MODEL"] = original_env_model
        elif "LLM_MODEL" in os.environ:
            del os.environ["LLM_MODEL"]
            
        if original_env_key:
            os.environ["LLM_API_KEY"] = original_env_key
        elif "LLM_API_KEY" in os.environ:
            del os.environ["LLM_API_KEY"]

def test_different_models():
    """Test avec diff√©rents mod√®les OpenRouter."""
    print("\n" + "="*60)
    print("TEST DE DIFF√âRENTS MOD√àLES")
    print("="*60)
    
    # Mod√®les √† tester
    models_to_test = [
        {
            "name": "OpenAI GPT-4o Mini",
            "model": "openai/gpt-4o-mini",
            "description": "Mod√®le √©conomique recommand√©"
        },
        {
            "name": "Google Gemini Flash (Gratuit)",
            "model": "google/gemini-2.0-flash-exp:free",
            "description": "Mod√®le gratuit pour tests"
        },
        {
            "name": "Claude 3.5 Haiku",
            "model": "anthropic/claude-3.5-haiku",
            "description": "Mod√®le Anthropic rapide"
        },
        {
            "name": "DeepSeek Chat",
            "model": "deepseek/deepseek-chat",
            "description": "Bon rapport qualit√©/prix"
        }
    ]
    
    # Cl√© API de test (remplacer par une vraie pour tester r√©ellement)
    test_api_key = os.environ.get("LLM_API_KEY", "sk-or-v1-test-key-12345")
    
    for model_info in models_to_test:
        print(f"\nüîß Test avec {model_info['name']}:")
        print(f"   Description: {model_info['description']}")
        
        try:
            # Cr√©er une configuration avec le mod√®le
            settings = Settings()
            mcp_params = {
                "LLM_MODEL": model_info["model"],
                "LLM_API_KEY": test_api_key
            }
            settings.update_from_mcp(mcp_params)
            
            # V√©rifier que la configuration est correcte
            assert settings.llm_model == model_info["model"]
            print(f"   ‚úÖ Configuration accept√©e: {settings.llm_model}")
            
            # Essayer d'initialiser le ToolLLMManager
            if test_api_key and test_api_key.startswith("sk-or-v1-"):
                try:
                    manager = ToolLLMManager(settings)
                    print(f"   ‚úÖ ToolLLMManager initialis√© avec succ√®s")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Erreur d'initialisation: {str(e)}")
            else:
                print(f"   ‚ÑπÔ∏è  Cl√© API de test uniquement - pas d'initialisation r√©elle")
                
        except Exception as e:
            print(f"   ‚ùå Erreur: {str(e)}")

def simulate_windsurf_config():
    """Simule la configuration depuis Windsurf MCP."""
    print("\n" + "="*60)
    print("SIMULATION DE CONFIGURATION WINDSURF")
    print("="*60)
    
    # Simuler diff√©rentes configurations Windsurf
    windsurf_configs = [
        {
            "name": "Configuration Minimale",
            "config": {
                "collegue": {
                    "serverUrl": "http://localhost:8088/mcp/"
                }
            }
        },
        {
            "name": "Configuration D√©veloppement",
            "config": {
                "collegue": {
                    "serverUrl": "http://localhost:8088/mcp/",
                    "LLM_MODEL": "google/gemini-2.0-flash-exp:free",
                    "LLM_API_KEY": "sk-or-v1-dev-key"
                }
            }
        },
        {
            "name": "Configuration Production",
            "config": {
                "collegue": {
                    "serverUrl": "https://collegue.example.com/mcp/",
                    "LLM_MODEL": "openai/gpt-4o",
                    "LLM_API_KEY": "sk-or-v1-prod-key"
                }
            }
        }
    ]
    
    for config_info in windsurf_configs:
        print(f"\nüìã {config_info['name']}:")
        print(f"   Config JSON: {json.dumps(config_info['config'], indent=6)}")
        
        # Extraire les param√®tres MCP
        collegue_config = config_info['config'].get('collegue', {})
        mcp_params = {}
        
        if 'LLM_MODEL' in collegue_config:
            mcp_params['LLM_MODEL'] = collegue_config['LLM_MODEL']
        if 'LLM_API_KEY' in collegue_config:
            mcp_params['LLM_API_KEY'] = collegue_config['LLM_API_KEY']
        
        # Appliquer la configuration
        settings = Settings()
        settings.update_from_mcp(mcp_params)
        
        print(f"\n   R√©sultat:")
        if mcp_params:
            print(f"   - Mod√®le configur√©: {settings.llm_model}")
            print(f"   - API Key pr√©sente: {bool(settings.llm_api_key)}")
        else:
            print(f"   - Utilise la configuration par d√©faut ou .env")
            print(f"   - Mod√®le: {settings.llm_model}")

def test_error_handling():
    """Test de la gestion d'erreurs."""
    print("\n" + "="*60)
    print("TEST DE GESTION D'ERREURS")
    print("="*60)
    
    # Test 1: Pas de cl√© API
    print("\n1. Test sans cl√© API:")
    settings = Settings()
    settings._mcp_llm_api_key = None
    settings.LLM_API_KEY = None
    
    try:
        manager = ToolLLMManager(settings)
        print("   ‚ùå Devrait lever une erreur sans cl√© API")
    except ValueError as e:
        print(f"   ‚úÖ Erreur correctement lev√©e: {str(e)}")
    
    # Test 2: Mod√®le invalide (sera accept√© par la config mais pourrait √©chouer √† l'ex√©cution)
    print("\n2. Test avec mod√®le invalide:")
    settings = Settings()
    mcp_params = {
        "LLM_MODEL": "invalid/model-name",
        "LLM_API_KEY": "sk-or-v1-test"
    }
    settings.update_from_mcp(mcp_params)
    
    try:
        manager = ToolLLMManager(settings)
        print(f"   ‚úÖ Configuration accept√©e (validation √† l'ex√©cution)")
        print(f"   - Mod√®le configur√©: {settings.llm_model}")
    except Exception as e:
        print(f"   ‚ùå Erreur inattendue: {str(e)}")

def main():
    """Fonction principale d'ex√©cution des tests."""
    print("\n" + "üöÄ"*30)
    print("TESTS DE CONFIGURATION MCP POUR COLL√àGUE")
    print("üöÄ"*30)
    
    try:
        # Ex√©cuter tous les tests
        test_config_priority()
        test_different_models()
        simulate_windsurf_config()
        test_error_handling()
        
        print("\n" + "="*60)
        print("‚úÖ TOUS LES TESTS SONT PASS√âS AVEC SUCC√àS!")
        print("="*60)
        print("\nüìå Prochaines √©tapes:")
        print("1. Configurer une vraie cl√© API OpenRouter dans .env")
        print("2. Tester avec Windsurf en utilisant mcp_config.json")
        print("3. Surveiller les logs avec: docker-compose logs collegue-app")
        print("4. Utiliser le client Python pour tester les outils")
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors des tests: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
